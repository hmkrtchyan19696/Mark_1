{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Sentiment:\n",
    "    NEGATIVE = 'NEGATIVE'\n",
    "    NEUTRAL = 'NEUTRAL'\n",
    "    POSITIVE = 'POSITIVE'\n",
    "\n",
    "class Review:\n",
    "    def __init__(self,text,score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "        \n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else:\n",
    "            return Sentiment.POSITIVE\n",
    "        \n",
    "class ReviewContainer:\n",
    "    def __init__(self,reviews):\n",
    "        self.reviews = reviews\n",
    "        \n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.reviews]\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        return [x.sentiment for x in self.reviews]\n",
    "        \n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews))\n",
    "        positive = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews))\n",
    "        positive_adjusted = positive[:len(negative)+20]\n",
    "        self.reviews = positive_adjusted + negative\n",
    "        random.shuffle(self.reviews)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'Books_small_10000.json'\n",
    "\n",
    "reviews = []\n",
    "with open(file_name) as file:\n",
    "    for line in file:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'],review['overall'],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('POSITIVE',\n",
       " \"My only complaint about this book is that it is much too short. I love this author and this series, and I can't wait for the next installment.\")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[10].sentiment, reviews[10].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(reviews,test_size=0.33,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6700, 3300)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('POSITIVE',\n",
       " 'This is a good part of the trilogy about three sisters and their inheritance. I also enjoyed it as a standalone.  I found it different from the Brodie series in that there was part of the paranormal and the past in all the books. This seems to be a new direction for Kat Martin, or perhaps it is because I am finished with the Brodie series and reading different series Kat has written.')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0].sentiment, train[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [x.text for x in train]\n",
    "y_train = [x.sentiment for x in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Ellington Darden provides a comprehensive and balanced discussion of high intensity training (HIT).  Some form of HIT is really beneficial for strength and size gains.  A lot of training modalities don't work as well when you reach 67 years old (like me) but modified HIT does work, even for an old f_ _k like me with structural issues.\",\n",
       " 'POSITIVE')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[5], y_train[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [x.text for x in test]\n",
    "y_test = [x.sentiment for x in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 3300)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_test), len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bags of words vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "x_train_vector = vectorizer.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a good part of the trilogy about three sisters and their inheritance. I also enjoyed it as a standalone.  I found it different from the Brodie series in that there was part of the paranormal and the past in all the books. This seems to be a new direction for Kat Martin, or perhaps it is because I am finished with the Brodie series and reading different series Kat has written. \n",
      " (6700, 26986)\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0],'\\n', x_train_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_vector = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf_svm = SVC(kernel = 'linear')\n",
    "\n",
    "clf_svm.fit(x_train_vector,y_train)\n",
    "\n",
    "clf_svm.predict(x_test_vector[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"I have read the trilogy now. What a brilliant story. Ms Pitts Caine has been painstaking in her research which delivers a detailed and richly engrossing story. I immediately recognised the characters from Cairo and The Tempering Agent and was excited to be reunited with them again and to learn more of their backgrounds.I particularly enjoyed the descriptions of Texas countryside - the lush greenery, the hills slightly rolled, the wide open skies; the 'Blackland Prairie'. I really felt I was on that journey with Mel and Addie.\",\n",
       " str)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[73], type(x_test[73])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_text_neg = [\"Don't like this book at all. I will not buy this book\"]\n",
    "text_neg = 'Disgusting'\n",
    "\n",
    "vectorizer.transform(random_text_neg).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_tree = DecisionTreeClassifier()\n",
    "\n",
    "clf_tree.fit(x_train_vector,y_train)\n",
    "\n",
    "clf_tree.predict(x_test_vector[87])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "\n",
    "clf_NB = GaussianNB()\n",
    "\n",
    "clf_NB.fit(x_train_vector.toarray(),y_train)\n",
    "\n",
    "clf_NB.predict(x_test_vector[87].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmkrt\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_lr = LogisticRegression()\n",
    "\n",
    "clf_lr.fit(x_train_vector,y_train)\n",
    "\n",
    "clf_lr.predict(x_test_vector[87])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8081818181818182,\n",
       " 0.7706060606060606,\n",
       " 0.8396969696969697,\n",
       " 0.6509090909090909)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mean Accuracy Score\n",
    "\n",
    "clf_svm.score(x_test_vector,y_test), clf_tree.score(x_test_vector,y_test), clf_lr.score(x_test_vector,y_test), clf_NB.score(x_test_vector.toarray(),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SVM:  [0.90228841 0.28125    0.40969163] \n",
      " Decision Tree:  [0.87830876 0.13804714 0.15915119] \n",
      " Logistic Regression  [0.92134039 0.3016158  0.40214477] \n",
      " Naive_Bayes:  [0.7933757  0.11292719 0.13623978]\n"
     ]
    }
   ],
   "source": [
    "#F1 Score\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(' SVM: ',f1_score(y_test,clf_svm.predict(x_test_vector),average=None,labels=[Sentiment.POSITIVE,Sentiment.NEUTRAL,Sentiment.NEGATIVE]),'\\n',\n",
    "      'Decision Tree: ',f1_score(y_test,clf_tree.predict(x_test_vector),average=None,labels=[Sentiment.POSITIVE,Sentiment.NEUTRAL,Sentiment.NEGATIVE]),'\\n',\n",
    "      'Logistic Regression ',f1_score(y_test,clf_lr.predict(x_test_vector),average=None,labels=[Sentiment.POSITIVE,Sentiment.NEUTRAL,Sentiment.NEGATIVE]),'\\n',\n",
    "     'Naive_Bayes: ',f1_score(y_test,clf_NB.predict(x_test_vector.toarray()),average=None,labels=[Sentiment.POSITIVE,Sentiment.NEUTRAL,Sentiment.NEGATIVE]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### So as we can see the model works very well in case of positive sentiments, however it works poorly in case of neutral and especially in negative cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['NEGATIVE', 'NEUTRAL', 'POSITIVE'], dtype='<U8'),\n",
       " array([ 39,  71, 560], dtype=int64))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements = np.asarray(y_train)\n",
    "\n",
    "np.unique(elements,return_counts=\"True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### So in order to resolve the issue a little bit, we need to have more data, so that the models will have more values for neutral and negative cases. I downloaded a bigger version of the same file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['NEGATIVE', 'NEUTRAL', 'POSITIVE'], dtype='<U8'),\n",
       " array([ 432,  643, 5625], dtype=int64))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements_new = np.asarray(y_train)\n",
    "\n",
    "np.unique(elements_new,return_counts=\"True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see the data still contains large number of positive review cases, so we need to evenly distribute our data so that our models don't get biased with positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(432, 452)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_container = ReviewContainer(train)\n",
    "test_container = ReviewContainer(test)\n",
    "\n",
    "train_container.evenly_distribute()\n",
    "\n",
    "x_train_cont = train_container.get_text()\n",
    "y_train_cont = train_container.get_sentiment()\n",
    "\n",
    "x_test_cont = test_container.get_text()\n",
    "y_test_cont = test_container.get_sentiment()\n",
    "\n",
    "y_train_cont.count(Sentiment.NEGATIVE), y_train_cont.count(Sentiment.POSITIVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "884"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_container.reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vector_cont = vectorizer.fit_transform(x_train_cont)\n",
    "x_test_vector_cont = vectorizer.transform(x_test_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3300, 3300)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM score: \n",
      "0.7427272727272727\n",
      "DT score: \n",
      "0.610909090909091\n",
      "LR score: \n",
      "0.7533333333333333\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def model_fit(model,x_train_vector_cont,y_train_cont):\n",
    "    model.fit(x_train_vector_cont,y_train_cont)\n",
    "    \n",
    "def calculate_f1_score(model,x_test_vector,y_test):\n",
    "    model_fit(model,x_train_vector_cont,y_train_cont)\n",
    "    f1_score(y_test,model.predict(x_test_vector_cont),average=None,labels=[Sentiment.POSITIVE,Sentiment.NEGATIVE])\n",
    "\n",
    "model_fit(clf_svm,x_train_vector_cont,y_train_cont)\n",
    "model_fit(clf_lr,x_train_vector_cont,y_train_cont)\n",
    "model_fit(clf_tree,x_train_vector_cont,y_train_cont)\n",
    "\n",
    "\n",
    "print('SVM score: ',clf_svm.score(x_test_vector_cont,y_test_cont), 'DT score: ',clf_tree.score(x_test_vector_cont,y_test_cont), 'LR score: ',clf_lr.score(x_test_vector_cont,y_test_cont),'\\n',sep='\\n')\n",
    "# print('SVM F1: ',calculate_f1_score(clf_svm,x_test_vector,y_test_cont), 'DT F1: ',calculate_f1_score(clf_tree,x_test_vector,y_test),\n",
    "#       'LR F1: ',calculate_f1_score(clf_lr,x_test_vector,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
